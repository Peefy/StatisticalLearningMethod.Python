# 第1章 统计学习方法概论

## 符号表

```python

class _Symbol:
    """
    符号表
    """
    def __init__(self):
        pass

    @property
    def symbol_dict(self):
        d = {}
        d['R'] = '实数集'
        d['R^n'] = 'n维实数向量空间,n维欧式空间'
        d['H'] = '希尔伯特空间'
        d['X'] = '输入空间'
        d['Y'] = '输出空间'
        d['x∈X'] = '输入,实例'
        d['y∈Y'] = '输出,标记'
        d['X'] = '输入随机变量'
        d['Y'] = '输出随机变量'
        d['T={(x1,y1),(x2,y2),...,(xn,yn)}'] = '训练输出集'
        d['N'] = '样本容量'
        d['(xi,yi)'] = '第i个训练数据点'
        d['x=(x(1),x(2),...,x(n))'] = '输入向量,n维实数向量'
        d['xi(j)'] = '输入向量xi的第j分量'
        d['P(X),P(Y)'] = '概率分布'
        d['P(X,Y)'] = '联合概率分布'
        d['F'] = '假设空间'
        d['f∈F'] = '模型参数'
        d['θ, w'] = '权值向量'
        d['w=(w1,w2,...,wn)^T'] = '偏置'
        d['J(f)'] = '模型的复杂度'
        d['R_emp'] = '经验风险或者经验损失'
        d['R_exp'] = '风险函数或期望损失'
        d['L'] = '损失函数，拉格朗日函数'
        d['η'] = '学习率'
        d['||·||1'] = 'L1范数'
        d['||·||2,||·||'] = 'L2范数'
        d['(x·x\')'] = '向量x和x\'的内积'
        d['H(X),H(p)'] = '熵'
        d['H(Y|X)'] = '条件熵'
        d['S'] = '分离超平面'
        d['α=(α1,α2,...,αn)^T'] = '拉格朗日乘子,对偶问题变量'
        d['αi'] = '对偶问题的第i个变量'
        d['K(x,z)'] = '核函数'
        d['sign(x)'] = '符号函数'
        d['I(x)'] = '指示函数'
        d['Z(x)'] = '规范化因子'
        return d

```

## 统计学习

统计学习就是计算机系统同构运用数据及统计方法提高系统性能的机器学习

统计学习方法三要素:模型,策略和算法

统计学习的对象是数据,它从数据出发,提取数据的特征,抽象出数据的模型,发现数据中的知识,又回到对数据的分析与预测中去.

统计学习的前提:关于数据的基本假设:同类数据具有一定的统计规律性

## 章节概要

1.统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行分析与预测
的一门学科。统计学习包括监督学习、非监督学习、半监督学习和强化学习

2.统计学习方法三要素----模型、策略、算法

3.监督学习概括：从给定有限的训练数据出发，假设数据是独立同分布的，而且假设模型数据某个假设空间，
应用评价准则，从假设空间中选取一个最优的模型，使它对已给训练数据及未知测试数据在给定评价标准意义下有最准确的预测

4.统计学习中，进行模型选择或者说提高学习的泛化能力是一个重要问题.如果只考虑减少训练误差,就可能产生过拟合现象。
模型选择的方法有正则化与交叉验证。学习方法泛化能力的分析使统计学习理论研究的重要课题

5.分类问题、标注问题和回归问题都是监督学习的重要问题。统计学习方法包括感知机、k近邻法、朴素贝叶斯法、
决策树、Logistic回归、最大熵模型、支持向量机、提升方法、EM算法、隐马尔可夫模型和条件随机场。
这些是主要的分类、标注以及回归方法。它们又可以归类为生成方法与判别方法
