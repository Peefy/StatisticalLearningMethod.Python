
class Chapter6:
    """
    第6章 逻辑斯谛回归与最大熵模型
    """
    def __init__(self):
        """
        第6章 逻辑斯谛回归与最大熵模型
        """
        pass

    def note(self):
        """
        chapter6 note
        """
        print('第6章 逻辑斯谛回归与最大熵模型')
        print('逻辑斯谛回归是统计学习中的经典分类方法.最大熵概率模型学习的一个准则,',
            '将其推广到分类问题得到最大熵模型.逻辑斯谛回归模型与最大熵模型都属于对数线性模型.')
        print('6.1 逻辑斯谛回归模型')
        print('6.1.1 逻辑斯谛分布')
        print('定义6.1（逻辑斯谛分布）设X是连续随机变量,X服从逻辑斯谛分布是指X具有下列分布函数和密度函数')
        print('  F(x)=P(X<=x)=1/(1+e^(-(x-u)/y))')
        print('  f(x)=F\'(x)=e^(-(x-u)/y)/(y(1+e^(-(x-u)/y)))')
        print('式中,u为位置参数,y>0为形状参数')
        print('逻辑斯谛分布的密度函数f(x)和分布函数F(x)的图形如图6.1所示.分布函数属于逻辑斯谛函数,',
            '其图形是一条S形曲线(sigmoid curve).该曲线以点(u,0.5)为中心对称,即满足:')
        print('  F(-x+u)-0.5=-F(x-u)+0.5')
        print('曲线在中心附近增长速度较快,在两端增长速度较慢.形状参数y的值越小,曲线在中心附近增长得越快.')
        print('6.1.2 二项逻辑斯谛回归模型')
        print('二项逻辑斯谛回归模型是一种分类模型,由条件概率分布P(Y|X)表示,形式为参数化的逻辑斯谛分布.',
            '这里,随机变量X取值为实数,随机变量Y取值为1或0.通过监督学习的方法来估计模型参数.')
        print('定义6.2(逻辑斯谛回归模型)二项逻辑斯谛回归模型是如下的条件概率分布:')
        print('   P(Y=1|x)=exp(wx+b)/(1+exp(wx+b))')
        print('   P(Y=0|x)=1/(1+exp(wx+b))')
        print('这里,x∈R^n,Y∈{0,1},w∈R^n和b∈R是参数,w称权值向量,b称为偏置,w·x为w和x的内积')
        print('现在考察逻辑斯谛回归模型的特点.一个事件的几率(odds)是指该事件发生的概率与该事件不发生的概率的比值.',
            '如果事件发生的概率的比值.如果事件发生的概率是p,那么该事件的几率是p/(1-p),',
            '该事件的对数几率(log odds)或logit函数是:logit(p)=logp/(1-p)')
        print('对逻辑斯谛回归而言:logP(Y=1|x)/(1-P(Y=1|x))=w·x')
        print('在逻辑斯谛回归模型中,输出Y=1的对数几率输入x的线性函数.或者说,',
            '输出Y=1的对数几率是由输入x的线性函数表示的模型,即逻辑斯谛回归模型')
        print('换一个角度看,考虑对输入x进行分类的线性函数w·x,其值域为实数域.',
            '注意：这里x∈R^(n+1),w∈R^(n+1).通过逻辑斯谛回归模型定义可以将线性函数w·x转换为概率：',
            'P(Y=1|x)=exp(wx)/(1+exp(wx))')
        print('这时,线性函数的值越接近正无穷,概率值就越接近于1;线性函数的值越接近负无穷,',
            '概率值就越接近0.这样的模型就是逻辑斯谛回归模型')
        print('6.1.3 模型参数估计')
        print('逻辑斯谛回归模型学习时,对于给定的训练数据集T={(x1,y1),(x2,y2),...,(xn,yn)},',
            '其中,xi∈R^n,yi∈{0,1},可以应用极大似然估计法估计模型参数,从而得到逻辑斯谛回归模型.')
        print('设:P(Y=1|x)=pi(x),P(Y=1|x)=1-pi(x)')
        print('对数似然函数为：L(w)=∑[yi(w·xi)-log(1+exp(w·xi))]')
        print('对L(w)求极大值,得到w的估计值')
        print('问题就变成了以对数似然函数为目标函数的最优化问题.逻辑斯谛回归学习中通常采用的方法是梯度下降法及拟牛顿法')
        print('假设w的极大似然估计值是w,那么学到的逻辑斯谛回归模型为:')
        print('  P(Y=1|x)=exp(w·x)/(1+exp(w·x))')
        print('  P(Y=0|x)=1/(1+exp(w·x))')
        print('6.1.4 多项式逻辑斯谛回归')
        print('之前介绍的逻辑斯谛回归模型是二项分类模型,用于二类分类.可以将推广为多项逻辑斯谛回归模型,',
            '用于多类分类.假设离散型随机变量Y的取值集合是{1,2,...,K},那么多项式逻辑斯谛回归模型是',
            'P(Y=k|x)=exp(wk·x)/(1+∑exp(wk·x)),k=1,2,...,K-1.',
            'P(Y=K|x)=1/(1+∑exp(wk·x));   这里x∈R^(n+1),wk∈R^(n+1)')
        print('二项逻辑斯谛回归的参数估计法也可以推广到多项逻辑斯谛回归.')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')

def main():
    chapter6.note()

if __name__ == '__main__':
    main()