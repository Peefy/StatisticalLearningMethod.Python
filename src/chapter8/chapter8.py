
class Chapter8:
    """
    第8章 提升方法
    """
    def __init__(self):
        """
        第8章 提升方法
        """
        pass

    def note(self):
        """
        chapter8 note
        """
        print('第8章 提升方法')

        print('提升(boosting)方法是一种常用的统计学习方法,应用广泛且有效.',
            '在分类问题中,通过改变训练样本的权重,学习多个分类器,',
            '并将这些分类器线性组合,提高分类的性能')
        print('8.1 提升方法AdaBoost算法')
        print('8.1.1 提升方法的基本思路')
        print('提升方法基于这样一种思想:对于一个复杂任务来说,',
            '将多个专家的判断进行适当的综合所得出的判断.',
            '要比其中任何一个专家单独的判断好.',
            '类似“三个臭皮匠顶个诸葛亮”')
        print('“强可学习”和“弱可学习”.',
            '在概率近似正确(PAC)学习框架中,一个概念(一个类),如果存在一个多项式的学习算法能够学习它',
            '并且正确率很高,那么就称这个概念是强可学习的;一个概念,',
            '如果存在一个多项式的学习算法能够学习它,学习的正确率仅比随机猜测略好,',
            '那么就称这个概念是弱可学习的.')
        print('在PAC学习的框架下,一个概念是强可学习的充分必要条件是这个概念是弱可学习的.')
        print('对于分类问题而言,给定一个训练样本集,求比较粗糙的分类规则(弱分类器)要比求精确的分类规则(强分类器)',
            '容易的多,提升方法就是从弱学习算法出发,反复学习,得到一系列弱分类器(又称为基本分类器),',
            '然后组合这些弱分类器,构成一个强分类器.大多数提升方法都是改变训练数据的概率分布(训练数据的权值分布)',
            '针对不同的训练数据分布调用弱学习算法学习一系列弱分类器')
        print('AdabBoost算法做法是:提高那些被前一轮弱分类器错误分类样本的权值,',
            '而降低那些被正确分类样本的权值,这样一来,那些没有得到正确分类的数据,',
            '由于其权值的加大而受到后一轮的弱分类器的更大关注.')
        print('于是,分类问题被一系列的弱分类器“分而治之”.弱分类器的组合,',
            'AdaBoost采取加权多数表决的方法.具体地,加大分类误差率小的弱分类器的权值,',
            '使其在表决中起较大的作用,减小分类误差率大的弱分类器的权值,使其在表决中起较小的作用.',
            'AdaBoost的巧妙之处就在于它将这些想法自然且有效地实现在一种算法里')
        print('8.1.2 AdaBoost算法')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')
        print('')

chapter8 = Chapter8()

def main():
    chapter8.note()

if __name__ == '__main__':
    main()